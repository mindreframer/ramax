defmodule EventStore.IntegrationTest do
  use ExUnit.Case, async: false
  doctest EventStore

  alias EventStore.Adapters.ETS
  alias EventStore.Adapters.SQLite

  @moduletag :integration

  setup_all do
    # Clean up any leftover test databases
    File.rm_rf!("tmp/test")
    File.mkdir_p!("tmp/test")
    :ok
  end

  describe "RMX005_5A_T1: Complete workflow: init → append → query → stream" do
    test "ETS adapter complete workflow" do
      # Initialize
      {:ok, store} = EventStore.new(ETS, table_name: :test_workflow_ets)

      # Append events
      {:ok, event_id_1, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.created",
          %{front: "Hello", back: "Hola"}
        )

      assert is_integer(event_id_1)
      assert event_id_1 > 0

      {:ok, event_id_2, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.updated",
          %{front: "Hi"},
          causation_id: event_id_1
        )

      assert event_id_2 == event_id_1 + 1

      {:ok, event_id_3, store} =
        EventStore.append(
          store,
          "base_card:card2",
          "basecard.created",
          %{front: "Goodbye", back: "Adiós"}
        )

      # Query events for entity
      {:ok, card1_events} = EventStore.get_events(store, "base_card:card1")
      assert length(card1_events) == 2

      [event1, event2] = card1_events
      assert event1.metadata.event_id == event_id_1
      assert event1.metadata.event_type == "basecard.created"
      assert event1.payload.front == "Hello"

      assert event2.metadata.event_id == event_id_2
      assert event2.metadata.event_type == "basecard.updated"
      assert event2.metadata.causation_id == event_id_1

      # Stream all events
      stream = EventStore.stream_all_events(store)
      all_events = Enum.to_list(stream)

      assert length(all_events) == 3
      assert Enum.map(all_events, & &1.metadata.event_id) == [event_id_1, event_id_2, event_id_3]

      # Get latest sequence
      {:ok, latest} = EventStore.get_latest_sequence(store)
      assert latest == event_id_3
    end

    test "SQLite adapter complete workflow" do
      db_path = "tmp/test/workflow_test.db"
      File.rm(db_path)

      # Initialize
      {:ok, store} = EventStore.new(SQLite, database: db_path)

      # Append events
      {:ok, event_id_1, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.created",
          %{front: "Hello", back: "Hola"}
        )

      assert is_integer(event_id_1)
      assert event_id_1 > 0

      {:ok, event_id_2, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.updated",
          %{front: "Hi"},
          causation_id: event_id_1
        )

      assert event_id_2 == event_id_1 + 1

      {:ok, event_id_3, store} =
        EventStore.append(
          store,
          "base_card:card2",
          "basecard.created",
          %{front: "Goodbye", back: "Adiós"}
        )

      # Query events for entity
      {:ok, card1_events} = EventStore.get_events(store, "base_card:card1")
      assert length(card1_events) == 2

      [event1, event2] = card1_events
      assert event1.metadata.event_id == event_id_1
      assert event1.metadata.event_type == "basecard.created"
      assert event1.payload.front == "Hello"

      assert event2.metadata.event_id == event_id_2
      assert event2.metadata.event_type == "basecard.updated"
      assert event2.metadata.causation_id == event_id_1

      # Stream all events
      stream = EventStore.stream_all_events(store)
      all_events = Enum.to_list(stream)

      assert length(all_events) == 3
      assert Enum.map(all_events, & &1.metadata.event_id) == [event_id_1, event_id_2, event_id_3]

      # Get latest sequence
      {:ok, latest} = EventStore.get_latest_sequence(store)
      assert latest == event_id_3
    end
  end

  describe "RMX005_5A_T2: Both adapters produce identical results" do
    test "same events appended to both adapters produce identical structures" do
      # Setup both adapters
      {:ok, ets_store} = EventStore.new(ETS, table_name: :test_identical_ets)
      db_path = "tmp/test/identical_test.db"
      File.rm(db_path)
      {:ok, sqlite_store} = EventStore.new(SQLite, database: db_path)

      # Define events to append
      events = [
        {"base_card:card1", "basecard.created", %{front: "A", back: "B"}},
        {"base_card:card1", "basecard.updated", %{front: "C"}},
        {"base_card:card2", "basecard.created", %{front: "D", back: "E"}},
        {"hosttrack:track1", "hosttrack.created", %{title: "Track 1"}}
      ]

      # Append to both stores
      {ets_event_ids, ets_store} =
        Enum.reduce(events, {[], ets_store}, fn {entity_id, event_type, payload}, {ids, store} ->
          {:ok, event_id, new_store} = EventStore.append(store, entity_id, event_type, payload)
          {ids ++ [event_id], new_store}
        end)

      {sqlite_event_ids, sqlite_store} =
        Enum.reduce(events, {[], sqlite_store}, fn {entity_id, event_type, payload},
                                                   {ids, store} ->
          {:ok, event_id, new_store} = EventStore.append(store, entity_id, event_type, payload)
          {ids ++ [event_id], new_store}
        end)

      # Event IDs should be sequential in both
      assert ets_event_ids == [1, 2, 3, 4]
      assert sqlite_event_ids == [1, 2, 3, 4]

      # Query card1 events from both
      {:ok, ets_card1_events} = EventStore.get_events(ets_store, "base_card:card1")
      {:ok, sqlite_card1_events} = EventStore.get_events(sqlite_store, "base_card:card1")

      # Should have same structure (ignoring timestamps and correlation_ids)
      assert length(ets_card1_events) == length(sqlite_card1_events)
      assert length(ets_card1_events) == 2

      # Compare event structure
      Enum.zip(ets_card1_events, sqlite_card1_events)
      |> Enum.each(fn {ets_event, sqlite_event} ->
        assert ets_event.metadata.event_id == sqlite_event.metadata.event_id
        assert ets_event.metadata.entity_id == sqlite_event.metadata.entity_id
        assert ets_event.metadata.event_type == sqlite_event.metadata.event_type
        assert ets_event.payload == sqlite_event.payload
      end)

      # Stream all events from both
      ets_all = EventStore.stream_all_events(ets_store) |> Enum.to_list()
      sqlite_all = EventStore.stream_all_events(sqlite_store) |> Enum.to_list()

      assert length(ets_all) == length(sqlite_all)
      assert length(ets_all) == 4

      # Compare all events
      Enum.zip(ets_all, sqlite_all)
      |> Enum.each(fn {ets_event, sqlite_event} ->
        assert ets_event.metadata.event_id == sqlite_event.metadata.event_id
        assert ets_event.metadata.entity_id == sqlite_event.metadata.entity_id
        assert ets_event.metadata.event_type == sqlite_event.metadata.event_type
        assert ets_event.payload == sqlite_event.payload
      end)
    end
  end

  describe "RMX005_5A_T3: Event immutability" do
    test "events cannot be modified after storage (no update operations)" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_immutable)

      {:ok, event_id, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.created",
          %{front: "Original", back: "Original"}
        )

      # Get the event
      {:ok, event} = EventStore.get_event(store, event_id)
      assert event.payload.front == "Original"

      # Verify no update operation exists (only append)
      refute function_exported?(EventStore, :update_event, 3)
      refute function_exported?(EventStore, :update_event, 4)
      refute function_exported?(EventStore, :delete_event, 2)

      # Append a correcting event instead
      {:ok, event_id_2, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.updated",
          %{front: "Corrected"},
          causation_id: event_id
        )

      # Original event unchanged
      {:ok, original_event} = EventStore.get_event(store, event_id)
      assert original_event.payload.front == "Original"
      assert original_event.payload.back == "Original"

      # New event exists
      {:ok, new_event} = EventStore.get_event(store, event_id_2)
      assert new_event.payload.front == "Corrected"
      assert new_event.metadata.causation_id == event_id
    end
  end

  describe "RMX005_5A_T4: Correlation ID tracing across events" do
    test "correlation_id can trace related events across entities" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_correlation)

      correlation_id = "batch-import-#{System.unique_integer([:positive])}"

      # Append multiple events with same correlation_id
      {:ok, event_id_1, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.created",
          %{front: "A"},
          correlation_id: correlation_id
        )

      {:ok, event_id_2, store} =
        EventStore.append(
          store,
          "base_card:card2",
          "basecard.created",
          %{front: "B"},
          correlation_id: correlation_id
        )

      {:ok, event_id_3, store} =
        EventStore.append(
          store,
          "base_card:card3",
          "basecard.created",
          %{front: "C"},
          correlation_id: correlation_id
        )

      # Append unrelated event
      {:ok, event_id_4, _store} =
        EventStore.append(
          store,
          "base_card:card4",
          "basecard.created",
          %{front: "D"}
        )

      # Verify correlation_id is stored
      {:ok, event1} = EventStore.get_event(store, event_id_1)
      {:ok, event2} = EventStore.get_event(store, event_id_2)
      {:ok, event3} = EventStore.get_event(store, event_id_3)
      {:ok, event4} = EventStore.get_event(store, event_id_4)

      assert event1.metadata.correlation_id == correlation_id
      assert event2.metadata.correlation_id == correlation_id
      assert event3.metadata.correlation_id == correlation_id
      assert event4.metadata.correlation_id != correlation_id

      # Find all events with same correlation_id (using stream)
      correlated_events =
        EventStore.stream_all_events(store)
        |> Enum.filter(&(&1.metadata.correlation_id == correlation_id))

      assert length(correlated_events) == 3
      event_ids = Enum.map(correlated_events, & &1.metadata.event_id)
      assert Enum.sort(event_ids) == [event_id_1, event_id_2, event_id_3]
    end
  end

  describe "RMX005_5A_T5: Causation ID tracking" do
    test "causation_id tracks event chains" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_causation)

      # Create initial event
      {:ok, event_id_1, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.created",
          %{front: "Initial"}
        )

      # Event caused by event_id_1
      {:ok, event_id_2, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.updated",
          %{front: "Updated"},
          causation_id: event_id_1
        )

      # Event caused by event_id_2
      {:ok, event_id_3, store} =
        EventStore.append(
          store,
          "base_card:card1",
          "basecard.updated",
          %{back: "Updated back"},
          causation_id: event_id_2
        )

      # Verify causation chain
      {:ok, event1} = EventStore.get_event(store, event_id_1)
      {:ok, event2} = EventStore.get_event(store, event_id_2)
      {:ok, event3} = EventStore.get_event(store, event_id_3)

      assert event1.metadata.causation_id == nil
      assert event2.metadata.causation_id == event_id_1
      assert event3.metadata.causation_id == event_id_2

      # Trace causation chain backwards
      chain = trace_causation_chain(store, event_id_3)
      assert chain == [event_id_3, event_id_2, event_id_1]
    end

    defp trace_causation_chain(store, event_id, acc \\ []) do
      {:ok, event} = EventStore.get_event(store, event_id)
      new_acc = [event_id | acc]

      case event.metadata.causation_id do
        nil -> Enum.reverse(new_acc)
        causation_id -> trace_causation_chain(store, causation_id, new_acc)
      end
    end
  end

  describe "RMX005_5A_T6: Performance - ETS append 10k events" do
    @tag timeout: 60_000
    test "ETS adapter appends 10k events quickly" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_perf_ets_append)

      {time_us, final_store} =
        :timer.tc(fn ->
          Enum.reduce(1..10_000, store, fn i, acc_store ->
            {:ok, _event_id, new_store} =
              EventStore.append(
                acc_store,
                "entity:#{rem(i, 100)}",
                "event.type",
                %{index: i, data: "payload_#{i}"}
              )

            new_store
          end)
        end)

      time_ms = time_us / 1000
      IO.puts("ETS: Appended 10k events in #{time_ms}ms (#{time_us / 10_000}μs per event)")

      # Verify all events were stored
      {:ok, latest} = EventStore.get_latest_sequence(final_store)
      assert latest == 10_000

      # Performance target: <10ms total is aggressive, let's verify reasonable performance
      # Typically ETS should handle 10k inserts in <100ms
      assert time_ms < 1000, "ETS append should be fast, took #{time_ms}ms"
    end
  end

  describe "RMX005_5A_T7: Performance - SQLite append 10k events" do
    @tag timeout: 120_000
    test "SQLite adapter appends 10k events within reasonable time" do
      db_path = "tmp/test/perf_append_test.db"
      File.rm(db_path)

      {:ok, store} = EventStore.new(SQLite, database: db_path)

      {time_us, final_store} =
        :timer.tc(fn ->
          Enum.reduce(1..10_000, store, fn i, acc_store ->
            {:ok, _event_id, new_store} =
              EventStore.append(
                acc_store,
                "entity:#{rem(i, 100)}",
                "event.type",
                %{index: i, data: "payload_#{i}"}
              )

            new_store
          end)
        end)

      time_ms = time_us / 1000
      IO.puts("SQLite: Appended 10k events in #{time_ms}ms (#{time_us / 10_000}μs per event)")

      # Verify all events were stored
      {:ok, latest} = EventStore.get_latest_sequence(final_store)
      assert latest == 10_000

      # Performance target: <500ms is ideal, but SQLite can be slower
      # Individual inserts without transactions can be slow
      assert time_ms < 30_000, "SQLite append took #{time_ms}ms, seems too slow"
    end
  end

  describe "RMX005_5A_T8: Performance - Entity query from 100k events" do
    @tag timeout: 120_000
    test "queries single entity from 100k events efficiently" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_perf_query)

      # Insert 100k events across 1000 entities
      IO.puts("Inserting 100k events...")

      final_store =
        Enum.reduce(1..100_000, store, fn i, acc_store ->
          {:ok, _event_id, new_store} =
            EventStore.append(
              acc_store,
              "entity:#{rem(i, 1000)}",
              "event.type",
              %{index: i}
            )

          new_store
        end)

      IO.puts("Querying entity:500...")

      # Query events for a specific entity (should have ~100 events)
      {time_us, {:ok, events}} =
        :timer.tc(fn ->
          EventStore.get_events(final_store, "entity:500")
        end)

      time_ms = time_us / 1000
      IO.puts("Query returned #{length(events)} events in #{time_ms}ms")

      # Verify correct number of events
      assert length(events) == 100

      # Performance target: <10ms
      assert time_ms < 100, "Entity query should be fast with index, took #{time_ms}ms"
    end
  end

  describe "RMX005_5A_T9: Performance - Stream 350k events with constant memory" do
    @tag timeout: 300_000
    @tag :expensive
    test "streaming 350k events uses constant memory" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_perf_stream)

      # Insert 350k events
      IO.puts("Inserting 350k events (this may take a while)...")

      final_store =
        Enum.reduce(1..350_000, store, fn i, acc_store ->
          if rem(i, 50_000) == 0, do: IO.puts("  Inserted #{i} events...")

          {:ok, _event_id, new_store} =
            EventStore.append(
              acc_store,
              "entity:#{rem(i, 1000)}",
              "event.type",
              %{index: i}
            )

          new_store
        end)

      IO.puts("Streaming all 350k events...")

      # Get memory before streaming
      :erlang.garbage_collect()
      memory_before = :erlang.memory(:total)

      # Stream and count (forces enumeration)
      {time_us, count} =
        :timer.tc(fn ->
          EventStore.stream_all_events(final_store, batch_size: 1000)
          |> Enum.reduce(0, fn _event, acc -> acc + 1 end)
        end)

      # Get memory after streaming
      :erlang.garbage_collect()
      memory_after = :erlang.memory(:total)

      memory_increase_mb = (memory_after - memory_before) / 1_024 / 1024
      time_ms = time_us / 1000

      IO.puts("Streamed #{count} events in #{time_ms}ms")
      IO.puts("Memory increase: #{memory_increase_mb}MB")

      assert count == 350_000

      # Memory should not grow linearly with event count
      # If we loaded all 350k events, memory would increase significantly
      # Streaming should keep memory relatively constant
      assert memory_increase_mb < 100, "Memory increase too large: #{memory_increase_mb}MB"
    end
  end

  describe "RMX005_5A_T10: Multiple event types" do
    test "different event types can coexist" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_event_types)

      # Append different event types
      {:ok, _id, store} =
        EventStore.append(store, 1, "base_card:1", "basecard.created", %{front: "A"})

      {:ok, _id, store} =
        EventStore.append(store, 1, "base_card:1", "basecard.updated", %{back: "B"})

      {:ok, _id, store} =
        EventStore.append(store, "hosttrack:1", "hosttrack.created", %{title: "Track"})

      {:ok, _id, store} =
        EventStore.append(store, "hosttrack:1", "hosttrack.updated", %{duration: 120})

      {:ok, _id, store} =
        EventStore.append(store, "deck:1", "deck.created", %{name: "My Deck"})

      {:ok, _id, store} =
        EventStore.append(store, "deck:1", "deck.card_added", %{card_id: "base_card:1"})

      # Query all events and group by type
      all_events = EventStore.stream_all_events(store) |> Enum.to_list()
      events_by_type = Enum.group_by(all_events, & &1.metadata.event_type)

      assert map_size(events_by_type) == 6

      assert length(events_by_type["basecard.created"]) == 1
      assert length(events_by_type["basecard.updated"]) == 1
      assert length(events_by_type["hosttrack.created"]) == 1
      assert length(events_by_type["hosttrack.updated"]) == 1
      assert length(events_by_type["deck.created"]) == 1
      assert length(events_by_type["deck.card_added"]) == 1
    end
  end

  describe "RMX005_5A_T11: Event type pattern querying" do
    test "can filter events by type pattern" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_type_pattern)

      # Append various basecard events
      {:ok, _id, store} =
        EventStore.append(store, 1, "base_card:1", "basecard.created", %{})

      {:ok, _id, store} =
        EventStore.append(store, 1, "base_card:1", "basecard.updated", %{})

      {:ok, _id, store} = EventStore.append(store, 1, "base_card:1", "basecard.deleted", %{})

      # Append hosttrack events
      {:ok, _id, store} =
        EventStore.append(store, "hosttrack:1", "hosttrack.created", %{})

      {:ok, _id, store} =
        EventStore.append(store, "hosttrack:1", "hosttrack.updated", %{})

      # Filter basecard.* events
      basecard_events =
        EventStore.stream_all_events(store)
        |> Enum.filter(&String.starts_with?(&1.metadata.event_type, "basecard."))

      assert length(basecard_events) == 3

      # Filter hosttrack.* events
      hosttrack_events =
        EventStore.stream_all_events(store)
        |> Enum.filter(&String.starts_with?(&1.metadata.event_type, "hosttrack."))

      assert length(hosttrack_events) == 2

      # Filter *.created events
      created_events =
        EventStore.stream_all_events(store)
        |> Enum.filter(&String.ends_with?(&1.metadata.event_type, ".created"))

      assert length(created_events) == 2
    end
  end

  describe "RMX005_5A_T12: Timestamp ordering across events" do
    test "events have correct timestamp ordering" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_timestamps)

      # Append events with small delays
      {:ok, event_id_1, store} =
        EventStore.append(store, 1, "entity:1", "event.type", %{order: 1})

      Process.sleep(10)

      {:ok, event_id_2, store} =
        EventStore.append(store, 1, "entity:1", "event.type", %{order: 2})

      Process.sleep(10)

      {:ok, event_id_3, store} =
        EventStore.append(store, 1, "entity:1", "event.type", %{order: 3})

      # Get events
      {:ok, event1} = EventStore.get_event(store, event_id_1)
      {:ok, event2} = EventStore.get_event(store, event_id_2)
      {:ok, event3} = EventStore.get_event(store, event_id_3)

      # Verify timestamps are in order
      assert DateTime.compare(event1.metadata.timestamp, event2.metadata.timestamp) in [:lt, :eq]
      assert DateTime.compare(event2.metadata.timestamp, event3.metadata.timestamp) in [:lt, :eq]

      # Verify timestamps are DateTime structs
      assert %DateTime{} = event1.metadata.timestamp
      assert %DateTime{} = event2.metadata.timestamp
      assert %DateTime{} = event3.metadata.timestamp

      # Verify timestamps are within reasonable range (last few seconds)
      now = DateTime.utc_now()
      diff1 = DateTime.diff(now, event1.metadata.timestamp, :second)
      assert diff1 < 60, "Timestamp should be recent"
    end
  end

  describe "RMX005_5A_T13: Error handling for database failures" do
    test "handles adapter init errors gracefully" do
      # Try to init SQLite with invalid path
      result = EventStore.new(SQLite, database: "/invalid/path/that/doesnt/exist.db")
      assert {:error, _reason} = result
    end

    test "handles missing event gracefully" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_error_handling)

      # Try to get non-existent event
      result = EventStore.get_event(store, 99999)
      assert {:error, :not_found} = result
    end

    test "get_events returns empty list for unknown entity" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_unknown_entity)

      {:ok, events} = EventStore.get_events(store, "unknown:entity")
      assert events == []
    end

    test "get_latest_sequence returns 0 for empty store" do
      {:ok, store} = EventStore.new(ETS, table_name: :test_empty_sequence)

      {:ok, latest} = EventStore.get_latest_sequence(store)
      assert latest == 0
    end
  end

  describe "RMX005_5A_T14: Adapter interchangeability" do
    test "can switch between adapters with same event structure" do
      # Create ETS store and append events
      {:ok, ets_store} = EventStore.new(ETS, table_name: :test_interchangeable_ets)

      {:ok, _id, ets_store} =
        EventStore.append(ets_store, "entity:1", "event.created", %{value: "A"})

      {:ok, _id, ets_store} =
        EventStore.append(ets_store, "entity:1", "event.updated", %{value: "B"})

      # Get events from ETS
      {:ok, ets_events} = EventStore.get_events(ets_store, "entity:1")

      # Create SQLite store and append same events
      db_path = "tmp/test/interchangeable_test.db"
      File.rm(db_path)
      {:ok, sqlite_store} = EventStore.new(SQLite, database: db_path)

      {:ok, _id, sqlite_store} =
        EventStore.append(sqlite_store, "entity:1", "event.created", %{value: "A"})

      {:ok, _id, sqlite_store} =
        EventStore.append(sqlite_store, "entity:1", "event.updated", %{value: "B"})

      # Get events from SQLite
      {:ok, sqlite_events} = EventStore.get_events(sqlite_store, "entity:1")

      # Both should have same structure
      assert length(ets_events) == length(sqlite_events)

      Enum.zip(ets_events, sqlite_events)
      |> Enum.each(fn {ets_event, sqlite_event} ->
        # Same metadata structure (ignoring timestamps and correlation_ids)
        assert ets_event.metadata.event_id == sqlite_event.metadata.event_id
        assert ets_event.metadata.entity_id == sqlite_event.metadata.entity_id
        assert ets_event.metadata.event_type == sqlite_event.metadata.event_type
        assert ets_event.metadata.causation_id == sqlite_event.metadata.causation_id

        # Same payload
        assert ets_event.payload == sqlite_event.payload

        # Both have timestamp and correlation_id
        assert %DateTime{} = ets_event.metadata.timestamp
        assert %DateTime{} = sqlite_event.metadata.timestamp
        assert is_binary(ets_event.metadata.correlation_id)
        assert is_binary(sqlite_event.metadata.correlation_id)
      end)
    end
  end
end
